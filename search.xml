<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[elasticsearch-路由和分片]]></title>
    <url>%2F2017%2F08%2F21%2Felasticsearch-%E8%B7%AF%E7%94%B1%E5%92%8C%E5%88%86%E7%89%87%2F</url>
    <content type="text"><![CDATA[路由一个文档到分片中当索引一个文档的时候，文档会被存储到一个主分片中。Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？给出一个公式：1shard = hash(routing) % number_of_primary_shards routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。 主分片和副分片如何交互假设有一个集群由三个节点组成。 它包含一个叫 blogs 的索引，有两个主分片，每个主分片有两个副本分片。相同分片的副本不会放在同一节点，则集群中分片的情况如下图所示： 请求可以发送到集群中的任一节点。每个节点都有能力处理任意请求，每个节点都知道集群中任意文档的位置。所以都可以将请求转发到需要的节点上。 新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片以下是一个索引的过程： 1, 客户端向 Node 1 发送新建、索引或者删除请求。 2, 节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在Node 3 上。 3, Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。 获取文档我们可以从主分片或者从其它任意副本分片检索文档以下是从主分片或者副本分片检索文档的步骤顺序： 1、客户端向 Node 1 发送获取请求。2、节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。3、Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。 在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的 update文档ES在更新文档时，其实是先搜索，再修改，最后同步到所有副本的操作。以下是部分更新一个文档的步骤： 1，客户端向 Node 1 发送更新请求。2，它将请求转发到主分片所在的 Node 3 。3，Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。4，如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。 一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。 consistency – 一致性保证在默认设置下，即使仅仅是在试图执行一个写操作之前，主分片都会要求 必须要有 规定数量(quorum)的分片副本处于活跃可用状态，才会去执行写操作(其中分片副本可以是主分片或者副本分片)。这是为了避免在发生网络分区故障（network partition）的时候进行写操作，进而导致数据不一致。规定数量即：1int( (primary + number_of_replicas) / 2 ) + 1 consistency可以设置为以下几种值： one : 只要主分片状态ok就可以执行写的操作。all : 必须要所有的主分片和副分片状态正确才允许执行写操作。quorum : 满足规定数量的副分片状态ok才执行写操作。]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch-冲突处理]]></title>
    <url>%2F2017%2F08%2F21%2Felasticsearch-%E5%86%B2%E7%AA%81%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[ES冲突处理和版本控制&ensp;&ensp;我们对ES文档的修改，都只会存储最近的一次修改结果，之前的所有修改都会被丢失。但是在很多应用场景中，可能只是将关系数据库的数据复制到es中使其可以被搜索。有时候是不能容忍数据被丢失的。其中的一个场景和下图类似： web_1 对 stock_count 所做的更改已经丢失，因为 web_2 不知道它的 stock_count 的拷贝已经过期。 结果我们会认为有超过商品的实际数量的库存，因为卖给顾客的库存商品并不存在，我们将让他们非常失望。 &ensp;&ensp;变更越频繁，读数据和更新数据的间隙越长，也就越可能丢失变更。&ensp;&ensp;在数据库领域中，有两种方法通常被用来确保并发更新时变更不会丢失： 悲观并发控制&ensp;&ensp;这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此阻塞访问资源以防止冲突。 一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。乐观并发控制&ensp;&ensp;Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。 然而，如果源数据在读写当中被修改，更新将会失败。应用程序接下来将决定该如何解决冲突。 例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。 乐观并发控制 – 通过version控制Elasticsearch 是分布式的。当文档创建、更新或删除时， 新版本的文档必须复制到集群中的其他节点。Elasticsearch 也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许 顺序是乱的 。 Elasticsearch 需要一种方法确保文档的旧版本不会覆盖新的版本。 每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。 当我们尝试通过重建文档的索引来保存修改，我们指定 version 为我们的修改会被应用的版本：12345PUT /website/blog/1?version=1 &#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Starting to get the hang of this...&quot;&#125; 然而，如果我们重新运行相同的索引请求，仍然指定 version=1 ， Elasticsearch 返回 409 Conflict HTTP 响应码1234567891011121314151617&#123; &quot;error&quot;: &#123; &quot;root_cause&quot;: [ &#123; &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[blog][1]: version conflict, current [2], provided [1]&quot;, &quot;index&quot;: &quot;website&quot;, &quot;shard&quot;: &quot;3&quot; &#125; ], &quot;type&quot;: &quot;version_conflict_engine_exception&quot;, &quot;reason&quot;: &quot;[blog][1]: version conflict, current [2], provided [1]&quot;, &quot;index&quot;: &quot;website&quot;, &quot;shard&quot;: &quot;3&quot; &#125;, &quot;status&quot;: 409&#125;]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch-分页搜索]]></title>
    <url>%2F2017%2F08%2F17%2Felasticsearch-%E5%88%86%E9%A1%B5%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[Elasticsearch–分页查询From&amp;Size VS scroll按照一般的查询流程来说，如果我想查询前10条数据：1，客户端请求发给某个节点2，节点转发给个个分片，查询每个分片上的前10条3，结果返回给节点，整合数据，提取前10条4，返回给请求客户端那么当我想要查询第10条到第20条的数据该怎么办呢？这个时候就用到分页查询了。 from-size”浅”分页它的原理很简单，就是查询前20条数据，然后截断前10条，只返回10-20的数据。这样其实白白浪费了前10条的查询。查询的方法:123456&#123; &quot;from&quot; : 0, &quot;size&quot; : 10, &quot;query&quot; : &#123; &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125; &#125;&#125; 其中，from定义了目标数据的偏移值，size定义当前返回的事件数目。默认from为0，size为10，即所有的查询默认仅仅返回前10条数据。 做过测试，越往后的分页，执行的效率越低。通过下图可以看出，刨去一些异常的数据，总体上还是会随着from的增加，消耗时间也会增加。而且数据量越大，效果越明显！ 也就是说，分页的偏移值越大，执行分页查询时间就会越长！scroll”深”分页相对于from和size的分页来说，使用scroll可以模拟一个传统数据的游标，记录当前读取的文档信息位置。这个分页的用法，不是为了实时查询数据，而是为了一次性查询大量的数据（甚至是全部的数据）。 因为这个scroll相当于维护了一份当前索引段的快照信息，这个快照信息是你执行这个scroll查询时的快照。在这个查询后的任何新索引进来的数据，都不会在这个快照中查询到。但是它相对于from和size，不是查询所有数据然后剔除不要的部分，而是记录一个读取的位置，保证下一次快速继续读取。&ensp;&ensp;使用的方法：123456789curl -XGET &apos;localhost:9200/twitter/tweet/_search?scroll=1m&apos; -d &apos;&#123; &quot;query&quot;: &#123; &quot;match&quot; : &#123; &quot;title&quot; : &quot;elasticsearch&quot; &#125; &#125;&#125;&apos; 测试from&amp;size VS scroll的性能初始化一个client对象：12345678910111213141516private static TransportClient client; private static String INDEX = &quot;index_name&quot;; private static String TYPE = &quot;type_name&quot;; public static TransportClient init()&#123; Settings settings = ImmutableSettings.settingsBuilder() .put(&quot;client.transport.sniff&quot;, true) .put(&quot;cluster.name&quot;, &quot;cluster_name&quot;) .build(); client = new TransportClient(settings).addTransportAddress(new InetSocketTransportAddress(&quot;localhost&quot;,9300)); return client; &#125; public static void main(String[] args) &#123; TransportClient client = init(); //这样就可以使用client执行查询了 &#125; 创建两个查询过程了 ，下面是from-size分页的执行代码：1234567891011System.out.println(&quot;from size 模式启动！&quot;);Date begin = new Date();long count = client.prepareCount(INDEX).setTypes(TYPE).execute().actionGet().getCount();SearchRequestBuilder requestBuilder = client.prepareSearch(INDEX).setTypes(TYPE).setQuery(QueryBuilders.matchAllQuery());for(int i=0,sum=0; sum&lt;count; i++)&#123; SearchResponse response = requestBuilder.setFrom(i).setSize(50000).execute().actionGet(); sum += response.getHits().hits().length; System.out.println(&quot;总量&quot;+count+&quot; 已经查到&quot;+sum);&#125;Date end = new Date();System.out.println(&quot;耗时: &quot;+(end.getTime()-begin.getTime())); 下面是scroll分页的执行代码，注意啊！scroll里面的size是相对于每个分片来说的，所以实际返回的数量是：分片的数量 x size123456789101112131415System.out.println(&quot;scroll 模式启动！&quot;);begin = new Date();SearchResponse scrollResponse = client.prepareSearch(INDEX) .setSearchType(SearchType.SCAN).setSize(10000).setScroll(TimeValue.timeValueMinutes(1)) .execute().actionGet(); count = scrollResponse.getHits().getTotalHits();//第一次不返回数据for(int i=0,sum=0; sum&lt;count; i++)&#123; scrollResponse = client.prepareSearchScroll(scrollResponse.getScrollId()) .setScroll(TimeValue.timeValueMinutes(8)) .execute().actionGet(); sum += scrollResponse.getHits().hits().length; System.out.println(&quot;总量&quot;+count+&quot; 已经查到&quot;+sum);&#125;end = new Date();System.out.println(&quot;耗时: &quot;+(end.getTime()-begin.getTime())); 可以看到仅仅30万，就相差接近一倍的性能，更何况是如今的大数据环境…因此，如果想要对全量数据进行操作，快换掉fromsize,使用scroll吧！]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 操作]]></title>
    <url>%2F2017%2F08%2F16%2Felasticsearch-%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[基础操作创建索引123456789PUT host:port/&#123;index&#125;&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 &#125; &#125;&#125; 更新索引配置1234567PUT host:port/&#123;index&#125;/_settings&#123; &quot;index&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 1 &#125;&#125; 删除索引1DELETE host:port/&#123;index&#125; 重建索引12345POST host:port/_reindex&#123;&quot;source&quot; : &#123;&quot;index&quot;:&quot;indexName&quot;&#125;,&quot;dest&quot; : &#123;&quot;index&quot;:&quot;new_indexName&quot;&#125;&#125; 创建索引类型映射1234567891011PUT host:port/&#123;index&#125;/_mapping/&#123;type&#125;&#123; &quot;properties&quot; : &#123; &quot;name&quot; : &#123; &quot;type&quot; : &quot;string&quot; &#125;, &quot;age&quot; : &#123; &quot;type&quot; : &quot;integer&quot; &#125; &#125;&#125; 获取索引类型字段映射1PUT host:port/&#123;index&#125;/_mapping/&#123;type&#125;/&#123;field&#125;/text 批量增加文档12345POST host:port/&#123;index&#125;/&#123;type&#125;/_bulk &#123; &quot;index&quot;: &#123; &quot;_id&quot;: 1 &#125;&#125; &#123; &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;, &quot;authors&quot;: [&quot;clinton gormley&quot;, &quot;zachary tong&quot;], &quot;summary&quot; : &quot;A distibuted real-time search and analytics engine&quot;, &quot;publish_date&quot; : &quot;2015-02-07&quot;, &quot;num_reviews&quot;: 20, &quot;publisher&quot;: &quot;oreilly&quot; &#125; &#123; &quot;index&quot;: &#123; &quot;_id&quot;: 2 &#125;&#125; &#123; &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, &quot;authors&quot;: [&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;], &quot;summary&quot; : &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;, &quot;publish_date&quot; : &quot;2013-01-24&quot;, &quot;num_reviews&quot;: 12, &quot;publisher&quot;: &quot;manning&quot; &#125; 增加文档12PUT host:port/&#123;index&#125;/&#123;type&#125;/&#123;id 可选&#125;&#123; &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, &quot;authors&quot;: [&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;], &quot;summary&quot; : &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;, &quot;publish_date&quot; : &quot;2013-01-24&quot;, &quot;num_reviews&quot;: 12, &quot;publisher&quot;: &quot;manning&quot; &#125; 查询文档1GET host:port/&#123;index&#125;/&#123;type&#125;/&#123;id&#125; 可选参数1，{source}=false : 不返回某个字段。2，{source}include,{source}exclude : 包含或过滤其中的某些字段。3，{source} : 只查询指定的某个字段。4, _primary : 在主节点进行查询。5, _local : 尽可能在本地节点进行查询。6, refresh : 设置为true时，会在搜索操作前刷新相关的分片，保证可以及时的查询到结果。但会消耗系统的资源，除非有必要，正常情况不需要设置。7, _mget : 多文档查询 通过Url参数搜索1host:port/&#123;index&#125;/&#123;type&#125;/_search?&#123;参数&#125; sort : 对指定字段进行排序，可以指定多个，按照书写顺序优先。分页查询 ：可以通过from size组合来进行。from表示从第几行开始，size表示查询多少条文档。size的大小不能大于index.max_result_window这个参数的设置。数据量较大的时候，推荐使用scroll来查询。后续会进行分析对比。 查询DSL查询和过滤的区别 查询 ： 检查内容和条件是否匹配，计算_score元字段表示匹配度。过滤 ： 不计算匹配得分，只是单纯的决定文档是否匹配。内容过滤主要用于过滤结构化的数据。 精确查找 term : 可以用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text），term 查询会查找我们指定的精确值。 123456789101112GET /my_store/products/_search&#123; &quot;query&quot; : &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;term&quot; : &#123; &quot;price&quot; : 20 &#125; &#125; &#125; &#125;&#125; terms : 查询多个精确值 123456789101112GET /my_store/products/_search&#123; &quot;query&quot; : &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;terms&quot; : &#123; &quot;price&quot; : [20, 30] &#125; &#125; &#125; &#125;&#125; 一定要了解 term 和 terms 是 包含（contains） 操作，而非 等值（equals)&emsp;&emsp;如果我们有一个 term（词项）过滤器 { “term” : { “tags” : “search” } } ，它会与以下两个文档 同时 匹配：12&#123; &quot;tags&quot; : [&quot;search&quot;] &#125;&#123; &quot;tags&quot; : [&quot;search&quot;, &quot;open_source&quot;] &#125; 可以通过对term增加tag_count参数来确保搜索结果的一致。123456789101112131415GET /my_index/my_type/_search&#123; &quot;query&quot;: &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;bool&quot; : &#123; &quot;must&quot; : [ &#123; &quot;term&quot; : &#123; &quot;tags&quot; : &quot;search&quot; &#125; &#125;, &#123; &quot;term&quot; : &#123; &quot;tag_count&quot; : 1 &#125; &#125; ] &#125; &#125; &#125; &#125;&#125; constant_score 查询 A query that wraps another query and simply returns a constant score equal to the query boost for every document in the filter.(一个包含另一个查询的查询，只返回等于过滤器中每个文档的查询常数boost。)可以使用它来取代只有 filter 语句的 bool 查询。 12345678910&#123; &quot;query&quot;: &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot;&#125; &#125;, &quot;boost&quot; : 1.2 &#125; &#125;&#125; 范围搜索&emsp;&emsp;抛出一个问题，如何在es中实现以下sql的功能？123SELECT documentFROM productsWHERE price BETWEEN 20 AND 40 在es中，通过range查询提供包含（inclusive）和不包含（exclusive）这两种范围表达式，可供组合的选项如下： gt: &gt; 大于（greater than）lt: &lt; 小于（less than）gte: &gt;= 大于或等于（greater than or equal to）lte: &lt;= 小于或等于（less than or equal to） 123456789101112131415GET /my_store/products/_search&#123; &quot;query&quot; : &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;range&quot; : &#123; &quot;price&quot; : &#123; &quot;gte&quot; : 20, &quot;lt&quot; : 40 &#125; &#125; &#125; &#125; &#125;&#125; 组合过滤器&emsp;&emsp;抛出个问题，怎样用 Elasticsearch 来表达下面的 SQL ？1234SELECT productFROM productsWHERE (price = 20 OR productID = &quot;XHDK-A-1293-#fJ3&quot;)AND (price != 30) 布尔过滤器&emsp;&emsp;一个 bool 过滤器由三部分组成：1234567&#123; &quot;bool&quot; : &#123; &quot;must&quot; : [], //与AND等价 &quot;should&quot; : [], //与OR等价 &quot;must_not&quot; : [], //与NOT等价 &#125;&#125; null处理在Es中，null, []空数组 和 [null] 所有这些都是等价的，它们无法存于倒排索引中。 exists 存在查询12345678910111213141516GET /my_index/posts/_search&#123; &quot;query&quot; : &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;exists&quot; : &#123; &quot;field&quot; : &quot;tags&quot; &#125; &#125; &#125; &#125;&#125;等价于SELECT tagsFROM postsWHERE tags IS NOT NULL missing 缺失查询12345678910111213141516GET /my_index/posts/_search&#123; &quot;query&quot; : &#123; &quot;constant_score&quot; : &#123; &quot;filter&quot; : &#123; &quot;missing&quot; : &#123; &quot;field&quot; : &quot;tags&quot; &#125; &#125; &#125; &#125;&#125;等价于SELECT tagsFROM postsWHERE tags IS NULL]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 基础]]></title>
    <url>%2F2017%2F08%2F16%2Felasticsearch-basic%2F</url>
    <content type="text"><![CDATA[elasticsearch几个重要的概念cluster 代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。 node 组成集群的每一个服务器称之为节点。 shards 代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。分片分主分片和副分片，每个文档都存储在一个分片中，当存储时，系统会首先存储在主分片中，然后会复制到不同的副本中。每个主分片有零个到多个副本，副分片主要有两个目的： 1，增加高可用性。 2，提高性能。 replicas 代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。 recovery 代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。 gateway 代表es索引的持久化存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再重新启动时就会从gateway中读取索引数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。 index／type／document 索引，具有相同结构的文档集合。对应关系数据库的databases.类型，在索引中，可以定义一个或多个类型，类型是索引的逻辑分区。对应关系数据库的table。文档，真正存储的数据内容。对应关系数据库的一行记录。]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器扩展点]]></title>
    <url>%2F2017%2F08%2F14%2Fspring-extendion%2F</url>
    <content type="text"><![CDATA[通过BeanPostProcessor定制Bean&#8194;&#8194;&#8194;&#8194;BeanPostProcessor定义了回调方法，通过实现这个回调方法，你可以提供你自己的(或者重写容器默认的)实例化逻辑，依赖分析逻辑等等。如果你想在Spring容器完成实例化，配置，和初始化bean之后，实例化一些自定义的逻辑，你可以插入一个或多个BeanPostProcessor的实现。&#8194;&#8194;&#8194;&#8194;可以配置多个BeanPostProcessor实例，通过设置order属性来控制这些BeanPostProcessors执行的顺序。 BeanPostProcessor作用在一个bean(或者对象)的实例上;也就是说，Spring IoC实例化一个bean实例之后， BeanPostProcessor，才开始进行处理。 BeanPostProcessor作用范围是每一个容器。这仅仅和你正在使用容器有关。如果你在一个容器中定义了一个BeanPostProcessor ，它将仅仅后置处理那个容器中的beans。换言之，一个容器中的beans不会被另一个容器中的BeanPostProcessor处理，即使这两个容器，具有相同的父类。&#8194;&#8194;&#8194;&#8194;ApplicationContext会自动地检测所有定义在配置元文件中，并实现了BeanPostProcessor接口的bean。该ApplicationContext注册这些beans作为后置处理器，使他们可以在bean创建完成之后被调用。bean后置处理器可以像其他bean一样部署到容器中。实现了BeanPostProcessor接口的类是特殊的,会被容器特殊处理。所有BeanPostProcessors和他们直接引用的 beans都会在容器启动的时候被实例化,作为ApplicationContext特殊启动阶段的一部分。 通过BeanFactoryPostProcessor定制Bean&#8194;&#8194;&#8194;&#8194;与BeanPostProcessor类似，但有一个主要的不同点：BeanFactoryPostProcessor操作bean的配置元数据；也就是说，Spring的IoC容器允许 BeanFactoryPostProcessor来读取配置元数据并在容器实例化任何bean(除了BeanFactoryPostProcessor)之前可以修改它。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-applicationContext]]></title>
    <url>%2F2017%2F08%2F11%2Fspring-applicationContext%2F</url>
    <content type="text"><![CDATA[ApplicationContextbeanFactory和ApplicationContext的区别 &#8194;&#8194;&#8194;&#8194;BeanFacotry是spring中比较原始的Factory。如XMLBeanFactory就是一种典型的BeanFactory。原始的BeanFactory无法支持spring的许多插件，如AOP功能、Web应用等。&#8194;&#8194;&#8194;&#8194;ApplicationContext接口,它由BeanFactory接口派生而来，因而提供BeanFactory所有的功能。ApplicationContext以一种更向面向框架的方式工作以及对上下文进行分层和实现继承，ApplicationContext包还提供了以下的功能： MessageSource, 提供国际化的消息访问 资源访问，如URL和文件: ApplicationContext扩展了ResourceLoader(资源加载器)接口，从而可以用来加载多个Resource，而BeanFactory是没有扩展ResourceLoader. 事件传播 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层.&#8194;&#8194;BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。&#8194;&#8194;BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册 功能扩展123456789101112131415161718192021222324252627282930313233343536373839404142434445464748protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // 设置类加载器为当前加载器 beanFactory.setBeanClassLoader(getClassLoader()); // 增加对el表达式的支持 beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); // 增加bean的属性编辑.例如Bean的属性为Date类型时，无法直接注入，则需要使用自定义的属性编辑器 beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 添加BeanPostProcessor beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 设置几个忽略自动装配的接口 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); // 注册依赖的类，一旦检测到属性为BeanFactory类型便会将beanFactory的实例注册进去 beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // Register early post-processor for detecting inner beans as ApplicationListeners. beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // 增加对AspectJ的支持 if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // Register default environment beans. if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125; &#125; BeanFactoryPostProcessor 容器级别的Bean扩展器 BeanFactoryPostProcessor的作用域范围是容器级的，仅对容器中的Bean进行后置处理。比较典型的几种 1， PropertyPlaceholderConfigurer : 对容器中的所有引用的属性值替换 1234567891011121314 public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; try &#123; Properties mergedProps = mergeProperties(); // Convert the merged properties, if necessary. convertProperties(mergedProps); // Let the subclass process the properties. processProperties(beanFactory, mergedProps); &#125; catch (IOException ex) &#123; throw new BeanInitializationException(&quot;Could not load properties&quot;, ex); &#125;&#125; 2， BeanDefinitionRegistryPostProcessor： 对BeanDefinition进行一些后置的自定义操作 123456789101112131415161718192021 import org.springframework.beans.BeansException; import org.springframework.beans.factory.support.BeanDefinitionRegistry; import org.springframework.beans.factory.support.BeanDefinitionRegistryPostProcessor; import org.springframework.beans.factory.support.RootBeanDefinition; import org.springframework.stereotype.Component; @Componentpublic class CustomServiceRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; RootBeanDefinition beanDefinition = new RootBeanDefinition(MyServiceImpl.class); //Service实现 serviceDefinition.setTargetType(MyService.class); //Service接口 serviceDefinition.setRole(BeanDefinition.ROLE_APPLICATION); registry.registerBeanDefinition(&quot;myBeanName&quot;, beanDefinition ); &#125;&#125; 应用 在Mybatis与Spring的整合中，就利用到了BeanDefinitionRegistryPostProcessor来对Mapper的BeanDefinition进行了后置的自定义处理。 在Spring的配置文件中，我们会配置以下代码来扫描Mapper：1234&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.rason.nba.mapper&quot; /&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt;&lt;/bean&gt; 其中org.mybatis.spring.mapper.MapperScannerConfigurer类就实现了BeanDefinitionRegistryPostProcessor接口来对Mapper进行自定义的注册操作。1234567891011121314151617181920212223// 代码有删减public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor&#123; public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, &#125;&#125;public class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner &#123; @Override public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123; Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages);//首先调用Spring默认的扫描装配操作 if (beanDefinitions.isEmpty()) &#123; &#125; else &#123; for (BeanDefinitionHolder holder : beanDefinitions) &#123;//然后循环对每一个BeanDefinition进行一些自定义的操作 GenericBeanDefinition definition = (GenericBeanDefinition) holder.getBeanDefinition(); definition.getPropertyValues().add(&quot;mapperInterface&quot;, definition.getBeanClassName()); definition.setBeanClass(MapperFactoryBean.class); definition.getPropertyValues().add(&quot;addToConfig&quot;, this.addToConfig); &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring annotation]]></title>
    <url>%2F2017%2F08%2F11%2Fspring-annotation%2F</url>
    <content type="text"><![CDATA[常用的Bean相关的注解@Repository、@Service、@Controller 和 @Component — 将类标识为Bean，由spring容器管理。通过上述注解标识的 Bean，其默认作用域是”singleton”，为了配合这四个注解，在标注 Bean 的同时能够指定 Bean 的作用域，引入了 @Scope 注解。使用该注解时只需提供作用域的名称。@PostConstruct、@PreDestroy — 指定生命周期回调方法，分别对应init-method 和 destroy-method 属性。@Required — 对bean的依赖进行检查。 标签提供了 dependency-check 属性用于进行依赖检查。该属性的取值包括以下几种： none – 默认不执行依赖检查。可以在 标签上使用 * default-dependency-check 属性改变默认值。 simple – 对原始基本类型和集合类型进行检查。 objects – 对复杂类型进行检查（除了 simple 所检查类型之外的其他类型）。 all – 对所有类型进行检查。 @Resource、@Autowired — Bean的自动装配策略。 no – 显式指定不使用自动装配。 byName – 如果存在一个和当前属性名字一致的 Bean，则使用该 Bean 进行注入。如果名称匹配但是类型不匹配，则抛出异常。如果没有匹配的类型，则什么也不做。 byType – 如果存在一个和当前属性类型一致的 Bean ( 相同类型或者子类型 )，则使用该 Bean 进行注入。byType 能够识别工厂方法，即能够识别 factory-method 的返回类型。如果存在多个类型一致的 Bean，则抛出异常。如果没有匹配的类型，则什么也不做。 constructor – 与 byType 类似，只不过它是针对构造函数注入而言的。如果当前没有与构造函数的参数类型匹配的 Bean，则抛出异常。使用该种装配模式时，优先匹配参数最多的构造函数。 autodetect – 根据 Bean 的自省机制决定采用 byType 还是 constructor 进行自动装配。如果 Bean 提供了默认的构造函数，则采用 byType；否则采用 constructor 进行自动装配。两者的区别 @Autowired and @Inject1, Matches by Type2, Restricts by Qualifiers3, Matches by Name@Resource1, Matches by Name2, Matches by Type3, Restricts by Qualifiers (ignored if match is found by name)‘@Autowired’ 和‘@Inject’的报错信息完全相同，他们都是通过 ‘AutowiredAnnotationBeanPostProcessor’ 类实现的依赖注入，二者具有可互换性。‘@Resource’通过 ‘CommonAnnotationBeanPostProcessor’ 类实现依赖注入]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring bean 加载流程]]></title>
    <url>%2F2017%2F08%2F10%2Fspring%2F</url>
    <content type="text"><![CDATA[几个重要的类 ResourceLoader: 资源加载器，根据给定的资源文件地址，返回对应的Resource。常用的有ClassPathResource,UrlResource,FileSystemResource. DocumentLoader: 定义从资源文件加载到转换为document的功能。 BeanDefinitionReader: 定义资源文件的读取并转化为BeanDefinition的功能。 DefaultBeanDefinitionDocumentReader：定义读取document并注册beanDefinition的功能。 BeanDefinitionParseDelegate: 定义解析element的各种方法。 BeanDefinitionRegistry: 定义对beanDefinition的各种增删改查的操作。 BeanDefinition: 对应配置文件中的一个bean标签,包含多种属性，例如className,lookUp,lazyInit,dependsOn,FactoryMethod Bean初始化的流程 从配置文件到bean的注册 1，资源文件的读取（ResourceLoader，DocumentLoader） 2，转化为beanDefinition对象（BeanDefinitionReader，DefaultBeanDefinitionDocumentReader，BeanDefinitionParseDelegate） 3，将bean注册到容器中（BeanDefinitionRegistry） Bean的加载spring如何解决依赖注入的循环依赖问题 通过构造器注入构成的循环依赖，此依赖是无法解决的，只能抛出BeanCurrentlyInCreationException异常表示循环依赖。对于setter注入造成的依赖是通过Spring容器提前暴露刚完成构造器注入但未完成其他步骤（如setter注入）的Bean来完成的，而且只能解决单例作用域的Bean循环依赖。 1、Spring容器创建单例“circleA” Bean，首先根据无参构造器创建Bean，并暴露一个“ObjectFactory ”用于返回一个提前暴露一个创建中的Bean，并将“circleA” 标识符放到“当前创建Bean池”；然后进行setter注入“circleB”；2、Spring容器创建单例“circleB” Bean，首先根据无参构造器创建Bean，并暴露一个“ObjectFactory”用于返回一个提前暴露一个创建中的Bean，并将“circleB” 标识符放到“当前创建Bean池”，然后进行setter注入“circleC”；3、Spring容器创建单例“circleC” Bean，首先根据无参构造器创建Bean，并暴露一个“ObjectFactory ”用于返回一个提前暴露一个创建中的Bean，并将“circleC” 标识符放到“当前创建Bean池”，然后进行setter注入“circleA”；进行注入“circleA”时由于提前暴露了“ObjectFactory”工厂从而使用它返回提前暴露一个创建中的Bean；4、最后在依赖注入“circleB”和“circleA”，完成setter注入。 对于“prototype”作用域Bean，Spring容器无法完成依赖注入，因为“prototype”作用域的Bean，Spring容器不进行缓存，因此无法提前暴露一个创建中的Bean。 在Bean加载过程中涉及的几种map singletonObjects: 用于保存beanName和创建的Bean实例之间的关系。 singletonFactories: 用于保存beanName和创建bean的工厂之间的关系。 earlySingletonObjects: 保存beanName和创建的bean实例之间的关系，与singletonObjects不同在于当一个bean被放入此map中时，即使还处于创建过程中，也可以通过getBean方法获取，主要用于检测循环依赖。 registeredSingletons：用于保存当前所有已注册的bean. 使用FactoryBean&#8194;&#8194;&#8194;&#8194;跟普通Bean不同，其返回的对象不是指定类的一个实例，其返回的是该FactoryBean的getObject方法所返回的对象。在Spring框架内部，有很多地方有FactoryBean的实现类，它们在很多应用如(Spring的AOP、ORM、事务管理)及与其它第三框架(ehCache)集成时都有体现. FactoryBean接口有3个方法：&#8194;&#8194;&#8194;&#8194;Object getObject():返回本工厂创建的对象实例。此实例也许是共享的，依赖于该工厂返回的是单例或者是原型。&#8194;&#8194;&#8194;&#8194;boolean isSingleton():如果FactoryBean返回的是单例,该方法返回值为true,否则为false&#8194;&#8194;&#8194;&#8194;Class getObjectType():返回对象类型。对象类型是getObject()方法返回的对象的类型，如果不知道的类型则返回null。 FactoryBean概念和接口在Spring框架中大量使用。Spring内置的有超过50个实现。&#8194;&#8194;&#8194;&#8194;当使用ApplicationContext的getBean()方法获取FactoryBean实例本身而不是它所产生的bean，则要使用&amp;符号+id。比如，现有FactoryBean，它有id，在容器上调用getBean(“myBean”)将返回FactoryBean所产生的bean，调用getBean(“&amp;myBean”)将返回FactoryBean它本身的实例。 Bean的创建creatBean&#8194;&#8194;&#8194;&#8194;在创建Bean对象时，如果没有需要覆盖的方法（beanDefinition.getMethodOverrides()为空，则默认使用反射的方式创建对象。如果有需要覆盖的方法，则需要使用动态代理的方式来实现。12345678910111213141516171819202122232425262728293031323334353637public Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) &#123; // Don&apos;t override the class with CGLIB if no overrides. if (bd.getMethodOverrides().isEmpty()) &#123; Constructor&lt;?&gt; constructorToUse; synchronized (bd.constructorArgumentLock) &#123; constructorToUse = (Constructor&lt;?&gt;) bd.resolvedConstructorOrFactoryMethod; if (constructorToUse == null) &#123; final Class&lt;?&gt; clazz = bd.getBeanClass(); if (clazz.isInterface()) &#123; throw new BeanInstantiationException(clazz, &quot;Specified class is an interface&quot;); &#125; try &#123; if (System.getSecurityManager() != null) &#123; constructorToUse = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Constructor&lt;?&gt;&gt;() &#123; @Override public Constructor&lt;?&gt; run() throws Exception &#123; return clazz.getDeclaredConstructor((Class[]) null); &#125; &#125;); &#125; else &#123; constructorToUse = clazz.getDeclaredConstructor((Class[]) null); &#125; bd.resolvedConstructorOrFactoryMethod = constructorToUse; &#125; catch (Throwable ex) &#123; throw new BeanInstantiationException(clazz, &quot;No default constructor found&quot;, ex); &#125; &#125; &#125; return BeanUtils.instantiateClass(constructorToUse); &#125; else &#123; // Must generate CGLIB subclass. return instantiateWithMethodInjection(bd, beanName, owner); &#125; &#125; populateBean 设置Bean属性注入&#8194;&#8194;&#8194;&#8194;Spring IoC容器根据Bean名称或者类型进行autowiring自动依赖注入 123456789101112131415161718protected void populateBean(String beanName, AbstractBeanDefinition mbd, BeanWrapper bw) &#123; //获取Bean定义的属性值，并对属性值进行处理 PropertyValues pvs = mbd.getPropertyValues(); …… //对依赖注入处理，首先处理autowiring自动装配的依赖注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); //根据Bean名称进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; //根据Bean类型进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; &#125; //对非autowiring的属性进行依赖注入处理 initializeBean 初始化Bean12345678910111213141516171819202122232425262728293031323334353637383940protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; //实现Aware接口，注入感知的对象 invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; //实现BeanPostProcessor,应用postProcessBeforeInitialization方法。 //在Bean的初始化前提供回调入口 if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; //应用配置的init-method方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, &quot;Invocation of init method failed&quot;, ex); &#125; //实现BeanPostProcessor,应用postProcessBeforeInitialization方法。 //在Bean的初始化之后提供回调入口 if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean; &#125; 上一张图]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
</search>
